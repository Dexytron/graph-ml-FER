{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:06.971804Z",
     "start_time": "2024-06-29T00:05:06.968995Z"
    }
   },
   "source": [
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, GINConv, GATConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:07.317201Z",
     "start_time": "2024-06-29T00:05:07.216583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data splits\n",
    "# dataset = 'fer2013'\n",
    "dataset = 'ck'\n",
    "train_data_path = dataset + '_data/train_data_70_20_10.pkl'\n",
    "val_data_path = dataset + '_data/val_data_70_20_10.pkl'\n",
    "test_data_path = dataset + '_data/test_data_70_20_10.pkl'\n",
    "\n",
    "with open(train_data_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(val_data_path, 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(test_data_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "adjacency_matrix = np.loadtxt('standard_mesh_adj_matrix.csv', delimiter=',')\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "# Add batch attribute to each data object\n",
    "for data in train_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "for data in val_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "for data in test_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n"
   ],
   "id": "8292bd1134db1345",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:07.901928Z",
     "start_time": "2024-06-29T00:05:07.882800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, GraphConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GIN, self).__init__()\n",
    "        self.device = device\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=True)\n",
    "        self.lin = torch.nn.Linear(hidden_dim * 4, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "class GCNSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GCNSAGE, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "class GINGAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GINGAT, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.conv2 = GATConv(hidden_dim, hidden_dim // 4, heads=4, concat=True)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "# Graph Conv\n",
    "class GConv(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GConv, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        return global_mean_pool(x, batch)\n",
    "    \n",
    "class GINBNorm(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GINBNorm, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def get_embeddings(self, data):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.x.to(torch.float), data.edge_index.to(torch.int64), data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        return global_mean_pool(x, batch)"
   ],
   "id": "7a482873ec7e5ec8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:08.309001Z",
     "start_time": "2024-06-29T00:05:08.304132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "            val_loss += criterion(out, data.y).item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "    return correct / total, val_loss / len(loader), all_labels, all_preds\n"
   ],
   "id": "633269b1ebf83fb6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:08.712041Z",
     "start_time": "2024-06-29T00:05:08.706225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def run_cross_validation(model_class,\n",
    "                         all_data, \n",
    "                         device, \n",
    "                         n_epochs=501,\n",
    "                         batch_size=32,\n",
    "                         n_splits=20, \n",
    "                         test_size=0.25,\n",
    "                         ):\n",
    "    splitter = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0)\n",
    "    all_train_losses = []\n",
    "    all_train_accuracies = []\n",
    "    all_xgb_test_accuracies = []\n",
    "    all_xgb_train_accuracies = []\n",
    "    all_test_losses = []\n",
    "    all_test_accuracies = []\n",
    "    print(\"Starting pipeline...\")\n",
    "    for i, (train_index, test_index) in enumerate(splitter.split(all_data)):\n",
    "        model = model_class(input_dim=3, hidden_dim=64, output_dim=output_dim, device=device)\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        train_data = [all_data[idx] for idx in train_index]\n",
    "        test_data = [all_data[idx] for idx in test_index]\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "        # Initialize model, optimizer, and criterion\n",
    "\n",
    "        # Calculate class weights\n",
    "        label_counts = np.bincount([data.y.item() for data in train_data])\n",
    "        class_weights = 1.0 / label_counts\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_acc) \n",
    "            test_acc, test_loss, test_labels, test_preds = evaluate(\n",
    "                model, \n",
    "                device, \n",
    "                test_loader, \n",
    "                criterion\n",
    "            )\n",
    "            test_losses.append(test_loss)\n",
    "            test_accuracies.append(test_acc)\n",
    "        \n",
    "        print(f'Split: {i+1}/{n_splits}, Test Loss: {test_loss:.4f}, Test Acc: {int(100 * test_acc):02d}%')\n",
    "        all_train_losses.append(train_losses)\n",
    "        all_train_accuracies.append(train_accuracies)\n",
    "        all_test_losses.append(test_losses)\n",
    "        all_test_accuracies.append(test_accuracies)\n",
    "    return all_test_losses, all_test_accuracies, all_train_losses, all_train_accuracies"
   ],
   "id": "17e14759381f34df",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:16.637975Z",
     "start_time": "2024-06-29T00:05:09.266357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_mapping = ['neutral', 'happiness', 'sadness', 'surprise', 'fear',\n",
    "                 'disgust', 'anger', 'contempt']\n",
    "output_dim = len(np.unique([data.y.item() for data in train_data]))\n",
    "models = {\n",
    "    \"GIN\": (GIN, 'mps'),\n",
    "    \"GAT\": (GAT, 'cpu'),\n",
    "    \"GCNSAGE\": (GCNSAGE, 'mps'),\n",
    "    \"GConv\": (GConv, 'mps'),\n",
    "    \"GINBNorm\": (GINBNorm, 'mps')\n",
    "}\n",
    "\n",
    "all_data = train_data + val_data + test_data\n",
    "output_dim = len(np.unique([data.y.item() for data in train_data]))\n",
    "results_dict = {}\n",
    "for model_name, (model, device) in models.items():\n",
    "    test_losses, test_accuracies, all_train_losses, all_train_accuracies, all_xgb_train_accuracies, all_xgb_test_accuracies = run_cross_validation(\n",
    "        model,\n",
    "        all_data, \n",
    "        device, \n",
    "        n_epochs=250,\n",
    "        n_splits=10\n",
    "    )\n",
    "    results_dict[model_name] = {\n",
    "        'all_test_losses': test_losses,\n",
    "        'all_test_accuracies': test_accuracies,\n",
    "        'all_train_losses': all_train_losses,\n",
    "        'all_train_accuracies': all_train_accuracies,\n",
    "        'all_xgb_train_accuracies': all_xgb_train_accuracies,\n",
    "        'all_xgb_test_accuracies': all_xgb_test_accuracies,\n",
    "    }"
   ],
   "id": "55071360bbe170c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m results_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m model_name, (model, device) \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 16\u001B[0m     test_losses, test_accuracies, all_train_losses, all_train_accuracies, all_xgb_train_accuracies, all_xgb_test_accuracies \u001B[38;5;241m=\u001B[39m \u001B[43mrun_cross_validation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mall_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m250\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     results_dict[model_name] \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall_test_losses\u001B[39m\u001B[38;5;124m'\u001B[39m: test_losses,\n\u001B[1;32m     25\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall_test_accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m: test_accuracies,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall_xgb_test_accuracies\u001B[39m\u001B[38;5;124m'\u001B[39m: all_xgb_test_accuracies,\n\u001B[1;32m     30\u001B[0m     }\n",
      "Cell \u001B[0;32mIn[11], line 43\u001B[0m, in \u001B[0;36mrun_cross_validation\u001B[0;34m(model_class, all_data, device, n_epochs, batch_size, n_splits, test_size)\u001B[0m\n\u001B[1;32m     39\u001B[0m criterion \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss(weight\u001B[38;5;241m=\u001B[39mclass_weights)\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_epochs):\n\u001B[0;32m---> 43\u001B[0m     train_loss, train_acc \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[1;32m     45\u001B[0m     train_accuracies\u001B[38;5;241m.\u001B[39mappend(train_acc) \n",
      "Cell \u001B[0;32mIn[10], line 7\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, device, train_loader, optimizer, criterion)\u001B[0m\n\u001B[1;32m      5\u001B[0m correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      6\u001B[0m total \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m      8\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m      9\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/loader/dataloader.py:27\u001B[0m, in \u001B[0;36mCollater.__call__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m     25\u001B[0m elem \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, BaseData):\n\u001B[0;32m---> 27\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_data_list\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfollow_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexclude_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default_collate(batch)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/data/batch.py:97\u001B[0m, in \u001B[0;36mBatch.from_data_list\u001B[0;34m(cls, data_list, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_data_list\u001B[39m(\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     87\u001B[0m     exclude_keys: Optional[List[\u001B[38;5;28mstr\u001B[39m]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     88\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[1;32m     89\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     batch, slice_dict, inc_dict \u001B[38;5;241m=\u001B[39m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    100\u001B[0m \u001B[43m        \u001B[49m\u001B[43mincrement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    101\u001B[0m \u001B[43m        \u001B[49m\u001B[43madd_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata_list\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mBatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    102\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m     batch\u001B[38;5;241m.\u001B[39m_num_graphs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(data_list)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m    107\u001B[0m     batch\u001B[38;5;241m.\u001B[39m_slice_dict \u001B[38;5;241m=\u001B[39m slice_dict  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/data/collate.py:142\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (add_batch \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stores[\u001B[38;5;241m0\u001B[39m], NodeStorage)\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m stores[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcan_infer_num_nodes):\n\u001B[0;32m--> 142\u001B[0m     repeats \u001B[38;5;241m=\u001B[39m [store\u001B[38;5;241m.\u001B[39mnum_nodes \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m store \u001B[38;5;129;01min\u001B[39;00m stores]\n\u001B[1;32m    143\u001B[0m     out_store\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;241m=\u001B[39m repeat_interleave(repeats, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m    144\u001B[0m     out_store\u001B[38;5;241m.\u001B[39mptr \u001B[38;5;241m=\u001B[39m cumsum(torch\u001B[38;5;241m.\u001B[39mtensor(repeats, device\u001B[38;5;241m=\u001B[39mdevice))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/data/collate.py:142\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (add_batch \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(stores[\u001B[38;5;241m0\u001B[39m], NodeStorage)\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m stores[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcan_infer_num_nodes):\n\u001B[0;32m--> 142\u001B[0m     repeats \u001B[38;5;241m=\u001B[39m [\u001B[43mstore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_nodes\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m store \u001B[38;5;129;01min\u001B[39;00m stores]\n\u001B[1;32m    143\u001B[0m     out_store\u001B[38;5;241m.\u001B[39mbatch \u001B[38;5;241m=\u001B[39m repeat_interleave(repeats, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m    144\u001B[0m     out_store\u001B[38;5;241m.\u001B[39mptr \u001B[38;5;241m=\u001B[39m cumsum(torch\u001B[38;5;241m.\u001B[39mtensor(repeats, device\u001B[38;5;241m=\u001B[39mdevice))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T00:05:21.912156Z",
     "start_time": "2024-06-29T00:05:19.960621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = GIN(input_dim=3, hidden_dim=64, output_dim=output_dim, device='mps')\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "# Initialize model, optimizer, and criterion\n",
    "\n",
    "# Calculate class weights\n",
    "label_counts = np.bincount([data.y.item() for data in train_data])\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc) \n",
    "    test_acc, test_loss, test_labels, test_preds = evaluate(\n",
    "        model, \n",
    "        device, \n",
    "        test_loader, \n",
    "        criterion\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)"
   ],
   "id": "8460f8f1789f4b4a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T01:10:27.124390Z",
     "start_time": "2024-06-29T01:09:23.458284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "explainer = Explainer(\n",
    "    model=model, \n",
    "    algorithm=GNNExplainer(\n",
    "    ),\n",
    "    explanation_type=\"model\",\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='log_probs'\n",
    "    )\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = []\n",
    "explanation = explainer(test_data[0], test_data[0].edge_index)\n",
    "explanations.append(explanation)"
   ],
   "id": "10399ece134dd41e",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# explanations for each node\u001B[39;00m\n\u001B[1;32m     15\u001B[0m explanations \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 16\u001B[0m explanation \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m explanations\u001B[38;5;241m.\u001B[39mappend(explanation)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/explain/explainer.py:196\u001B[0m, in \u001B[0;36mExplainer.__call__\u001B[0;34m(self, x, edge_index, target, index, **kwargs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    193\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    194\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m should not be provided for the explanation \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    195\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexplanation_type\u001B[38;5;241m.\u001B[39mvalue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 196\u001B[0m     prediction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_target(prediction)\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(index, \u001B[38;5;28mint\u001B[39m):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch_geometric/explain/explainer.py:115\u001B[0m, in \u001B[0;36mExplainer.get_prediction\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 115\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtrain(training)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T01:03:38.689476Z",
     "start_time": "2024-06-29T01:03:38.680805Z"
    }
   },
   "cell_type": "code",
   "source": "test_data",
   "id": "7703c03e5cb8c30b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T18:05:11.815011Z",
     "start_time": "2024-06-29T04:36:03.755744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# Specify the coordinates for the click (example: x=100, y=200)\n",
    "x = 20\n",
    "y = 250\n",
    "\n",
    "# Define the interval in seconds\n",
    "interval = 60\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Move the mouse to the specified coordinates\n",
    "        pyautogui.moveTo(x, y)\n",
    "        \n",
    "        # Click at the current mouse position\n",
    "        pyautogui.click()\n",
    "\n",
    "        # Wait for the specified interval\n",
    "        time.sleep(interval)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Script terminated by user\")"
   ],
   "id": "d474fbe9664c56ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script terminated by user\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "556f904a47daf693"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
