{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:26.608656Z",
     "start_time": "2024-06-29T23:44:26.604341Z"
    }
   },
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, GINConv, GATConv\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:26.923826Z",
     "start_time": "2024-06-29T23:44:26.828913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data splits\n",
    "# dataset = 'fer2013'\n",
    "dataset = 'ck'\n",
    "train_data_path = dataset + '_data/train_data_70_20_10.pkl'\n",
    "val_data_path = dataset + '_data/val_data_70_20_10.pkl'\n",
    "test_data_path = dataset + '_data/test_data_70_20_10.pkl'\n",
    "\n",
    "with open(train_data_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(val_data_path, 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(test_data_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "adjacency_matrix = np.loadtxt('standard_mesh_adj_matrix.csv', delimiter=',')\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "# Add batch attribute to each data object\n",
    "for data in train_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in val_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in test_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "    \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n"
   ],
   "id": "8292bd1134db1345",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:02:13.012569Z",
     "start_time": "2024-06-30T00:02:12.994693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, GraphConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GIN, self).__init__()\n",
    "        self.device = device\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=True)\n",
    "        self.lin = torch.nn.Linear(hidden_dim * 4, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GCNSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GCNSAGE, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GConv(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GConv, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GINBNorm(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GINBNorm, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "id": "7a482873ec7e5ec8",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:29.926458Z",
     "start_time": "2024-06-29T23:44:29.917607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "            val_loss += criterion(out, data.y).item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "    return correct / total, val_loss / len(loader), all_labels, all_preds\n"
   ],
   "id": "633269b1ebf83fb6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:02:22.836912Z",
     "start_time": "2024-06-30T00:02:21.470614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dim = len(np.unique([data.y.item() for data in train_data]))\n",
    "device = 'cpu'\n",
    "### CHANGE THE NAME OF THE MODEL HERE\n",
    "model = GINBNorm(input_dim=3, hidden_dim=64, output_dim=output_dim)\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "# Initialize model, optimizer, and criterion\n",
    "\n",
    "# Calculate class weights\n",
    "label_counts = np.bincount([data.y.item() for data in train_data])\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc) \n",
    "    test_acc, test_loss, test_labels, test_preds = evaluate(\n",
    "        model, \n",
    "        device, \n",
    "        test_loader, \n",
    "        criterion\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)"
   ],
   "id": "8460f8f1789f4b4a",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:02:23.932088Z",
     "start_time": "2024-06-30T00:02:23.723297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "explainer = Explainer(\n",
    "    model=model, \n",
    "    algorithm=GNNExplainer(\n",
    "    ),\n",
    "    explanation_type=\"model\",\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='log_probs'\n",
    "    )\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = []\n",
    "explanation = explainer(test_data[0].x, test_data[0].edge_index, target=None, batch=test_data[0].batch)\n",
    "explanations.append(explanation)"
   ],
   "id": "10399ece134dd41e",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:02:24.536198Z",
     "start_time": "2024-06-30T00:02:24.533251Z"
    }
   },
   "cell_type": "code",
   "source": "explanations[0].node_mask",
   "id": "18fb1aeea712f8aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2509, 0.3193, 0.2632],\n",
       "        [0.2688, 0.3090, 0.3346],\n",
       "        [0.2634, 0.3420, 0.2775],\n",
       "        ...,\n",
       "        [0.3139, 0.2656, 0.2618],\n",
       "        [0.2939, 0.2530, 0.3052],\n",
       "        [0.5824, 0.2852, 0.2665]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ce7e9ecc220f7d0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
