{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:26.608656Z",
     "start_time": "2024-06-29T23:44:26.604341Z"
    }
   },
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, GINConv, GATConv\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:26.923826Z",
     "start_time": "2024-06-29T23:44:26.828913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data splits\n",
    "# dataset = 'fer2013'\n",
    "dataset = 'ck'\n",
    "train_data_path = dataset + '_data/train_data_70_20_10.pkl'\n",
    "val_data_path = dataset + '_data/val_data_70_20_10.pkl'\n",
    "test_data_path = dataset + '_data/test_data_70_20_10.pkl'\n",
    "\n",
    "with open(train_data_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(val_data_path, 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(test_data_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "adjacency_matrix = np.loadtxt('standard_mesh_adj_matrix.csv', delimiter=',')\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "# Add batch attribute to each data object\n",
    "for data in train_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in val_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in test_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "    \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n"
   ],
   "id": "8292bd1134db1345",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:27.762677Z",
     "start_time": "2024-06-29T23:44:27.754782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, GraphConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GIN, self).__init__()\n",
    "        self.device = device\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ],
   "id": "7a482873ec7e5ec8",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:29.926458Z",
     "start_time": "2024-06-29T23:44:29.917607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "            val_loss += criterion(out, data.y).item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "    return correct / total, val_loss / len(loader), all_labels, all_preds\n"
   ],
   "id": "633269b1ebf83fb6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:44:52.589017Z",
     "start_time": "2024-06-29T23:44:51.501093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dim = len(np.unique([data.y.item() for data in train_data]))\n",
    "device = 'cpu'\n",
    "model = GIN(input_dim=3, hidden_dim=64, output_dim=output_dim)\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "# Initialize model, optimizer, and criterion\n",
    "\n",
    "# Calculate class weights\n",
    "label_counts = np.bincount([data.y.item() for data in train_data])\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc) \n",
    "    test_acc, test_loss, test_labels, test_preds = evaluate(\n",
    "        model, \n",
    "        device, \n",
    "        test_loader, \n",
    "        criterion\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)"
   ],
   "id": "8460f8f1789f4b4a",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:45:19.542578Z",
     "start_time": "2024-06-29T23:45:19.307849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "explainer = Explainer(\n",
    "    model=model, \n",
    "    algorithm=GNNExplainer(\n",
    "    ),\n",
    "    explanation_type=\"model\",\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='log_probs'\n",
    "    )\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = []\n",
    "explanation = explainer(test_data[0].x, test_data[0].edge_index, target=None, batch=test_data[0].batch)\n",
    "explanations.append(explanation)"
   ],
   "id": "10399ece134dd41e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T23:45:19.546751Z",
     "start_time": "2024-06-29T23:45:19.543657Z"
    }
   },
   "cell_type": "code",
   "source": "explanations[0].node_mask",
   "id": "18fb1aeea712f8aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3941, 0.2902, 0.2483],\n",
       "        [0.3253, 0.2537, 0.2726],\n",
       "        [0.5924, 0.3026, 0.2492],\n",
       "        ...,\n",
       "        [0.3682, 0.2549, 0.2372],\n",
       "        [0.2897, 0.2464, 0.3042],\n",
       "        [0.3595, 0.2721, 0.2743]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m explainer \u001B[38;5;241m=\u001B[39m GNNExplainer_(model)\n\u001B[1;32m      3\u001B[0m node_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m----> 4\u001B[0m graph_feat_mask, edge_mask \u001B[38;5;241m=\u001B[39m \u001B[43mexplainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexplain_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m ax, G \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mvisualize_subgraph(node_idx,edge_index1, edge_mask, y\u001B[38;5;241m=\u001B[39mtest_data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39my)\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "Cell \u001B[0;32mIn[6], line 296\u001B[0m, in \u001B[0;36mGNNExplainer_.explain_graph\u001B[0;34m(self, x, edge_index, **kwargs)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexplain_graph\u001B[39m(\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    286\u001B[0m     x: Tensor,\n\u001B[1;32m    287\u001B[0m     edge_index: Tensor,\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    289\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Tensor, Tensor]:\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_explainer\u001B[38;5;241m.\u001B[39mmodel_config\u001B[38;5;241m.\u001B[39mtask_level \u001B[38;5;241m=\u001B[39m ModelTaskLevel\u001B[38;5;241m.\u001B[39mgraph\n\u001B[1;32m    292\u001B[0m     explanation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_explainer(\n\u001B[1;32m    293\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m    294\u001B[0m         x,\n\u001B[1;32m    295\u001B[0m         edge_index,\n\u001B[0;32m--> 296\u001B[0m         target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_initial_prediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    297\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    298\u001B[0m     )\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_output(explanation, edge_index)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 275\u001B[0m, in \u001B[0;36mGNNExplainer_.get_initial_prediction\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mtraining\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m--> 275\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_explainer\u001B[38;5;241m.\u001B[39mmodel_config\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m\n\u001B[1;32m    277\u001B[0m         ModelMode\u001B[38;5;241m.\u001B[39mmulticlass_classification):\n\u001B[1;32m    278\u001B[0m     out \u001B[38;5;241m=\u001B[39m out\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/graph-ml-FER/lib/python3.8/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "execution_count": 7,
   "source": "",
   "id": "181e12a6c98a4ff7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T01:03:38.689476Z",
     "start_time": "2024-06-29T01:03:38.680805Z"
    }
   },
   "cell_type": "code",
   "source": "test_data",
   "id": "7703c03e5cb8c30b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468]),\n",
       " Data(x=[468, 3], edge_index=[2, 2644], y=[1], bbox=[6], batch=[468])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "556f904a47daf693"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
