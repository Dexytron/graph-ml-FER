{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T14:28:10.730045Z",
     "start_time": "2024-07-02T14:28:10.711088Z"
    }
   },
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import global_mean_pool, GINConv, GATConv\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:28:11.443099Z",
     "start_time": "2024-07-02T14:28:10.954164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data splits\n",
    "# dataset = 'fer2013'\n",
    "dataset = 'ck'\n",
    "train_data_path = dataset + '_data/train_data_70_20_10.pkl'\n",
    "val_data_path = dataset + '_data/val_data_70_20_10.pkl'\n",
    "test_data_path = dataset + '_data/test_data_70_20_10.pkl'\n",
    "\n",
    "with open(train_data_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open(val_data_path, 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "with open(test_data_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "adjacency_matrix = np.loadtxt('standard_mesh_adj_matrix.csv', delimiter=',')\n",
    "G = nx.from_numpy_array(adjacency_matrix)\n",
    "\n",
    "# Add batch attribute to each data object\n",
    "for data in train_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in val_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "for data in test_data:\n",
    "    data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "    data.device = 'cpu'\n",
    "    \n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif val_loss > self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = val_loss\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss\n"
   ],
   "id": "8292bd1134db1345",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:28:13.560458Z",
     "start_time": "2024-07-02T14:28:13.544275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import BatchNorm\n",
    "from torch_geometric.nn import GATConv, GCNConv, SAGEConv, GraphConv\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GIN, self).__init__()\n",
    "        self.device = device\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(input_dim, hidden_dim, heads=4, concat=True)\n",
    "        self.conv2 = GATConv(hidden_dim * 4, hidden_dim, heads=4, concat=True)\n",
    "        self.lin = torch.nn.Linear(hidden_dim * 4, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GCNSAGE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GCNSAGE, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GConv(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GConv, self).__init__()\n",
    "        self.conv1 = GraphConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GraphConv(hidden_dim, hidden_dim)\n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "class GINBNorm(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, device='cpu'):\n",
    "        super(GINBNorm, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.bn1 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(hidden_dim, hidden_dim), torch.nn.ReLU(), torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.conv2 = GINConv(nn2)\n",
    "        self.bn2 = BatchNorm(hidden_dim)\n",
    "        \n",
    "        self.lin = torch.nn.Linear(hidden_dim, output_dim)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, data, edge_index, batch):\n",
    "        data = data.to(self.device)\n",
    "        x, edge_index, batch = data.to(torch.float), edge_index.to(torch.int64), batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "id": "7a482873ec7e5ec8",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:28:18.541018Z",
     "start_time": "2024-07-02T14:28:18.533546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            total += data.y.size(0)\n",
    "            val_loss += criterion(out, data.y).item()\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(data.y.cpu().numpy())\n",
    "    return correct / total, val_loss / len(loader), all_labels, all_preds\n"
   ],
   "id": "633269b1ebf83fb6",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T15:07:30.248254Z",
     "start_time": "2024-07-02T15:06:31.834138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_dim = len(np.unique([data.y.item() for data in train_data]))\n",
    "device = ('cpu')\n",
    "### CHANGE THE NAME OF THE MODEL HERE\n",
    "model = GIN(input_dim=3, hidden_dim=64, output_dim=output_dim)\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "batch_size = 32\n",
    "n_epochs = 250\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "# Initialize model, optimizer, and criterion\n",
    "\n",
    "# Calculate class weights\n",
    "label_counts = np.bincount([data.y.item() for data in train_data])\n",
    "class_weights = 1.0 / label_counts\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_acc = train(model, device, train_loader, optimizer, criterion)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc) \n",
    "    test_acc, test_loss, test_labels, test_preds = evaluate(\n",
    "        model, \n",
    "        device, \n",
    "        test_loader, \n",
    "        criterion\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)"
   ],
   "id": "8460f8f1789f4b4a",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T14:31:18.912056Z",
     "start_time": "2024-07-02T14:31:18.647382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "explainer = Explainer(\n",
    "    model=model, \n",
    "    algorithm=GNNExplainer(\n",
    "    ),\n",
    "    explanation_type=\"model\",\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='log_probs'\n",
    "    )\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = []\n",
    "explanation = explainer(test_data[0].x, test_data[0].edge_index, target=None, batch=test_data[0].batch)\n",
    "explanations.append(explanation)"
   ],
   "id": "10399ece134dd41e",
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "selected_node = train_data[0]\n",
    "\n",
    "# Create an empty figure\n",
    "# fig = go.Figure()\n",
    "\n",
    "x_vals = [value[0] for value in selected_node.x]\n",
    "y_vals = [value[1] for value in selected_node.x]\n",
    "z_vals = [value[2] for value in selected_node.x]\n",
    "weights = np.mean(explanations[0].node_mask.numpy(), 1)\n",
    "\n",
    "fig = go.Figure(go.Scatter3d(\n",
    "    x=x_vals,\n",
    "    y=y_vals,\n",
    "    z=z_vals,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=weights,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Weights'),\n",
    "        opacity=0.8,\n",
    "    ),\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=f'3D Landmarks for Expression',\n",
    "    scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='browser')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T14:31:24.184785Z",
     "start_time": "2024-07-02T14:31:23.861370Z"
    }
   },
   "id": "fc7c49cdc04a48e0",
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "def run_explanation_vis(graph_id):\n",
    "    explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(\n",
    "    ),\n",
    "    explanation_type=\"model\",\n",
    "    node_mask_type=\"attributes\",\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='graph',\n",
    "        return_type='log_probs'\n",
    "    )\n",
    "    )\n",
    "    # explanations for each node\n",
    "    explanation = explainer(test_data[graph_id].x, test_data[graph_id].edge_index, target=None, batch=test_data[graph_id].batch)\n",
    "\n",
    "    # Create an empty figure\n",
    "    # fig = go.Figure()\n",
    "\n",
    "    x_vals = [value[0] for value in selected_node.x]\n",
    "    y_vals = [value[1] for value in selected_node.x]\n",
    "    z_vals = [value[2] for value in selected_node.x]\n",
    "    weights = np.mean(explanation.node_mask.numpy(), 1)\n",
    "\n",
    "    fig = go.Figure(go.Scatter3d(\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        z=z_vals,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=weights,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='Weights'),\n",
    "            opacity=0.8,\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "    # Update layout for better visualization\n",
    "    fig.update_layout(\n",
    "        title=f'3D Landmarks for Expression',\n",
    "        scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show(renderer='browser')\n",
    "    \n",
    "run_explanation_vis(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T14:38:26.728076Z",
     "start_time": "2024-07-02T14:38:26.090136Z"
    }
   },
   "id": "de0938a4412e3f25",
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "source": [
    "explainer = Explainer(\n",
    "model=model,\n",
    "algorithm=GNNExplainer(\n",
    "),\n",
    "explanation_type=\"model\",\n",
    "node_mask_type=\"attributes\",\n",
    "edge_mask_type='object',\n",
    "model_config=dict(\n",
    "    mode='multiclass_classification',\n",
    "    task_level='graph',\n",
    "    return_type='log_probs'\n",
    ")\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = np.zeros_like(test_data[0].x)\n",
    "for graph_id in range(len(test_data)):\n",
    "    explanations += explainer(test_data[graph_id].x, test_data[graph_id].edge_index, target=None, batch=test_data[graph_id].batch).node_mask.numpy()\n",
    "\n",
    "# Create an empty figure\n",
    "# fig = go.Figure()\n",
    "\n",
    "x_vals = [value[0] for value in selected_node.x]\n",
    "y_vals = [value[1] for value in selected_node.x]\n",
    "z_vals = [value[2] for value in selected_node.x]\n",
    "weights = np.mean(explanations, 1)\n",
    "weights = (weights - weights.min()) / (weights.max() - weights.min())\n",
    "fig = go.Figure(go.Scatter3d(\n",
    "    x=x_vals,\n",
    "    y=y_vals,\n",
    "    z=z_vals,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=weights,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Weights'),\n",
    "        opacity=0.8,\n",
    "    ),\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=f'3D Landmarks for Expression',\n",
    "    scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='browser')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-02T15:07:43.837353Z",
     "start_time": "2024-07-02T15:07:30.249661Z"
    }
   },
   "id": "c1e0a43c06532ac9",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GIN looks at half of the face, nose is symmetrically considered, cheeks and eyes are the most important parts\n",
    "# GAT looks at the whole face, lower face and edges are the most important parts\n",
    "# SAGE only considers half of the face, top right, nose is not important, cheek, eye and the edge of the lips\n",
    "# similar to SAGE, but also looks at the other half of the face for the space between eye and nose, much more focus on one side of the face\n"
   ],
   "id": "3d69baded73ffa2c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explainer = Explainer(\n",
    "model=model,\n",
    "algorithm=GNNExplainer(\n",
    "),\n",
    "explanation_type=\"model\",\n",
    "node_mask_type=\"attributes\",\n",
    "edge_mask_type='object',\n",
    "model_config=dict(\n",
    "    mode='multiclass_classification',\n",
    "    task_level='graph',\n",
    "    return_type='log_probs'\n",
    ")\n",
    ")\n",
    "# explanations for each node\n",
    "explanations = np.zeros_like(test_data[0].x)\n",
    "for graph_id in range(len(test_data)):\n",
    "    explanations += explainer(test_data[graph_id].x, test_data[graph_id].edge_index, target=None, batch=test_data[graph_id].batch).node_mask.numpy()\n",
    "\n",
    "# Create an empty figure\n",
    "# fig = go.Figure()\n",
    "\n",
    "x_vals = [value[0] for value in selected_node.x]\n",
    "y_vals = [value[1] for value in selected_node.x]\n",
    "z_vals = [value[2] for value in selected_node.x]\n",
    "weights = np.mean(explanations, 1)\n",
    "weights = (weights - weights.min()) / (weights.max() - weights.min())\n",
    "fig = go.Figure(go.Scatter3d(\n",
    "    x=x_vals,\n",
    "    y=y_vals,\n",
    "    z=z_vals,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=weights,\n",
    "        colorscale='Viridis',\n",
    "        colorbar=dict(title='Weights'),\n",
    "        opacity=0.8,\n",
    "    ),\n",
    "))\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(\n",
    "    title=f'3D Landmarks for Expression',\n",
    "    scene=dict(xaxis_title='X', yaxis_title='Y', zaxis_title='Z'),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer='browser')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2c60769aa977408"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
